{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988962fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Original train shape: (1460, 81)\n",
      "Original test shape: (1459, 80)\n",
      "Combined shape after FE, before other processing: (2919, 91)\n",
      "Final processed train shape: (1460, 251)\n",
      "Final processed test shape: (1459, 251)\n",
      "\n",
      "--- Tryb Predykcji: Pomijanie treningu, wczytywanie modelu z pliku ---\n",
      "Pomyślnie wczytano model z pliku: best_house_price_model.pth\n",
      "\n",
      "Generowanie predykcji dla zbioru testowego...\n",
      "Zapisano przewidywania (1459 wierszy) do pliku submission_final.csv\n",
      "\n",
      "Zakończono.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ==============================================\n",
    "# KONFIGURACJA MODELU\n",
    "# ==============================================\n",
    "config = {\n",
    "    \"batch_size\": 32,\n",
    "    \"learning_rate\": 0.003,\n",
    "    \"epochs\": 2000,\n",
    "    \"early_stopping_patience\": 100,\n",
    "    \"hidden_layers\": [512, 256, 128, 64],\n",
    "    \"dropout_rate\": 0.3,\n",
    "    \"use_dropout\": True,\n",
    "    \"validation_size\": 0.2,\n",
    "    \"random_state\": 42,\n",
    "    \"target_transform\": True, \n",
    "    \"weight_decay\": 1e-4,\n",
    "    \"use_scheduler\": True,\n",
    "    \"scheduler_patience\": 25,\n",
    "    \"scheduler_factor\": 0.3,\n",
    "    \"min_lr\": 1e-7,\n",
    "    \"model_save_path\": \"best_house_price_model.pth\", \n",
    "    \"submission_file_name\": \"submission_final.csv\" \n",
    "}\n",
    "\n",
    "# ==============================================\n",
    "# WCZYTYWANIE DANYCH\n",
    "# ==============================================\n",
    "def load_data(train_path=\"Data/train.csv\", test_path=\"Data/test.csv\"):\n",
    "    try:\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        print(f\"Original train shape: {train_df.shape}\")\n",
    "        print(f\"Original test shape: {test_df.shape}\")\n",
    "        if train_df.empty or test_df.empty:\n",
    "            raise ValueError(\"Loaded train_df or test_df is empty!\")\n",
    "        return train_df, test_df\n",
    "    except FileNotFoundError:\n",
    "        print(f\"FATAL: {train_path} or {test_path} not found.\")\n",
    "        raise SystemExit(\"Exiting due to missing data files.\")\n",
    "\n",
    "# ==============================================\n",
    "# PRZETWARZANIE DANYCH I FEATURE ENGINEERING\n",
    "# ==============================================\n",
    "def preprocess_data(train_df, test_df, target_transform=True):\n",
    "   \n",
    "    test_ids = test_df['Id']\n",
    "    \n",
    "    train_index = train_df.index\n",
    "    test_index = test_df.index\n",
    "    train_df['is_train'] = 1\n",
    "    test_df['is_train'] = 0\n",
    "    \n",
    "    all_features_df = pd.concat((train_df, test_df), ignore_index=True).copy()\n",
    "\n",
    "    # --- Feature Engineering ---\n",
    "    all_features_df['HouseAge'] = all_features_df['YrSold'] - all_features_df['YearBuilt']\n",
    "    all_features_df['RemodAge'] = all_features_df['YrSold'] - all_features_df['YearRemodAdd']\n",
    "    all_features_df['IsRemodeled'] = (all_features_df['YearRemodAdd'] != all_features_df['YearBuilt']).astype(int)\n",
    "    all_features_df.loc[all_features_df['YearRemodAdd'] == all_features_df['YearBuilt'], 'RemodAge'] = all_features_df['HouseAge']\n",
    "\n",
    "    base_sf_cols = ['GrLivArea', 'TotalBsmtSF', 'BsmtFinSF1', 'BsmtFinSF2', \n",
    "                    'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch']\n",
    "    for col in base_sf_cols:\n",
    "        if col not in all_features_df.columns: all_features_df[col] = 0\n",
    "        all_features_df[col] = all_features_df[col].fillna(0)\n",
    "\n",
    "    all_features_df['TotalSF'] = all_features_df['GrLivArea'] + all_features_df['TotalBsmtSF']\n",
    "    all_features_df['TotalFinishedSF'] = all_features_df['GrLivArea'] + all_features_df['BsmtFinSF1'] + all_features_df['BsmtFinSF2']\n",
    "    all_features_df['TotalPorchSF'] = all_features_df['OpenPorchSF'] + all_features_df['EnclosedPorch'] + \\\n",
    "                                   all_features_df['3SsnPorch'] + all_features_df['ScreenPorch']\n",
    "\n",
    "    bath_cols = ['FullBath', 'HalfBath', 'BsmtFullBath', 'BsmtHalfBath']\n",
    "    for col in bath_cols:\n",
    "        if col not in all_features_df.columns: all_features_df[col] = 0\n",
    "        all_features_df[col] = all_features_df[col].fillna(0)\n",
    "    all_features_df['TotalBath'] = all_features_df['FullBath'] + 0.5 * all_features_df['HalfBath'] + \\\n",
    "                                all_features_df['BsmtFullBath'] + 0.5 * all_features_df['BsmtHalfBath']\n",
    "\n",
    "    all_features_df['HasPool'] = (all_features_df.get('PoolArea', pd.Series(0, index=all_features_df.index)).fillna(0) > 0).astype(int)\n",
    "    all_features_df['HasFireplace'] = (all_features_df.get('Fireplaces', pd.Series(0, index=all_features_df.index)).fillna(0) > 0).astype(int)\n",
    "    all_features_df['HasGarage'] = (all_features_df.get('GarageArea', pd.Series(0, index=all_features_df.index)).fillna(0) > 0).astype(int)\n",
    "    \n",
    "    all_features_df['BsmtFinToTotalBsmt_Ratio'] = (all_features_df['BsmtFinSF1'] + all_features_df['BsmtFinSF2']) / (all_features_df['TotalBsmtSF'] + 1e-6)\n",
    "    all_features_df['LotArea_x_GrLivArea_Ratio'] = all_features_df['GrLivArea'] / (all_features_df['LotArea'] + 1e-6)\n",
    "\n",
    "    train_df_fe = all_features_df[all_features_df['is_train'] == 1].drop(columns=['is_train'])\n",
    "    test_df_fe = all_features_df[all_features_df['is_train'] == 0].drop(columns=['is_train', 'SalePrice'])\n",
    "    train_df_fe.index = train_index\n",
    "    test_df_fe.index = test_index\n",
    "    train_df = train_df_fe\n",
    "    test_df = test_df_fe\n",
    "\n",
    "    train_df = train_df.drop('Id', axis=1)\n",
    "    test_df = test_df.drop('Id', axis=1)\n",
    "\n",
    "    if target_transform and 'SalePrice' in train_df.columns:\n",
    "        train_df['SalePrice'] = np.log1p(train_df['SalePrice'])\n",
    "\n",
    "    y_train_full = None\n",
    "    split_point = 0\n",
    "    if 'SalePrice' in train_df.columns:\n",
    "        y_train_full = train_df['SalePrice'].copy()\n",
    "        train_df_features = train_df.drop(['SalePrice'], axis=1)\n",
    "        all_df = pd.concat((train_df_features.reset_index(drop=True), \n",
    "                            test_df.reset_index(drop=True)), \n",
    "                           ignore_index=True)\n",
    "        split_point = len(train_df_features)\n",
    "    else:\n",
    "        all_df = pd.concat((train_df.reset_index(drop=True), \n",
    "                            test_df.reset_index(drop=True)), \n",
    "                           ignore_index=True)\n",
    "        split_point = len(train_df)\n",
    "        \n",
    "    print(f\"Combined shape after FE, before other processing: {all_df.shape}\")\n",
    "\n",
    "    if 'LotFrontage' in all_df.columns and 'Neighborhood' in all_df.columns:\n",
    "        all_df['LotFrontage'] = all_df.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))\n",
    "        all_df['LotFrontage'] = all_df['LotFrontage'].fillna(all_df['LotFrontage'].median())\n",
    "    elif 'LotFrontage' in all_df.columns:\n",
    "        all_df['LotFrontage'] = all_df['LotFrontage'].fillna(all_df['LotFrontage'].median())\n",
    "\n",
    "    cols_fillna_none = ['Alley', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
    "                        'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                        'PoolQC', 'Fence', 'MasVnrType', 'MiscFeature']\n",
    "    for col in cols_fillna_none:\n",
    "        if col in all_df.columns: all_df[col] = all_df[col].fillna('None')\n",
    "\n",
    "    num_cols_with_na = all_df.select_dtypes(include=np.number).isnull().sum()\n",
    "    num_cols_to_fill = num_cols_with_na[num_cols_with_na > 0].index\n",
    "    if len(num_cols_to_fill) > 0:\n",
    "        for col in num_cols_to_fill: all_df[col] = all_df[col].fillna(all_df[col].median())\n",
    "\n",
    "    cat_cols_with_na = all_df.select_dtypes(include='object').isnull().sum()\n",
    "    cat_cols_to_fill = cat_cols_with_na[cat_cols_with_na > 0].index\n",
    "    if len(cat_cols_to_fill) > 0:\n",
    "        for col in cat_cols_to_fill: all_df[col] = all_df[col].fillna(all_df[col].mode()[0])\n",
    "    \n",
    "    if all_df.isnull().sum().sum() > 0:\n",
    "        print(f\"Warning: NaNs still present after imputation ({all_df.isnull().sum().sum()} total). Filling with 0.\")\n",
    "        all_df = all_df.fillna(0)\n",
    "\n",
    "    ordinal_mappings = {\n",
    "        'ExterQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}, 'ExterCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "        'BsmtQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}, 'BsmtCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "        'BsmtExposure': {'None': 0, 'No': 1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "        'BsmtFinType1': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "        'BsmtFinType2': {'None': 0, 'Unf': 1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ': 5, 'GLQ': 6},\n",
    "        'HeatingQC': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}, 'KitchenQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "        'FireplaceQu': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "        'GarageQual': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5}, 'GarageCond': {'None': 0, 'Po': 1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex': 5},\n",
    "        'PoolQC': {'None': 0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex': 4}, 'Fence': {'None': 0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv': 4},\n",
    "        'LotShape': {'IR3': 0, 'IR2': 1, 'IR1': 2, 'Reg': 3}, 'LandSlope': {'Sev': 0, 'Mod': 1, 'Gtl': 2},\n",
    "        'PavedDrive': {'N': 0, 'P': 1, 'Y': 2}, 'Street': {'Grvl': 0, 'Pave': 1},\n",
    "        'Alley': {'None': 0, 'Grvl': 1, 'Pave': 2}, 'CentralAir': {'N': 0, 'Y': 1},\n",
    "        'Utilities': {'ELO': 0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
    "        'GarageFinish': {'None': 0, 'Unf': 1, 'RFn': 2, 'Fin': 3},\n",
    "        'Functional': {'Sal':0, 'Sev':1, 'Maj2':2, 'Maj1':3, 'Mod':4, 'Min2':5, 'Min1':6, 'Typ':7}\n",
    "    }\n",
    "    for col, mapping in ordinal_mappings.items():\n",
    "        if col in all_df.columns: all_df[col] = all_df[col].map(mapping).fillna(0)\n",
    "            \n",
    "    if 'OverallQual' in all_df.columns and 'OverallCond' in all_df.columns:\n",
    "        all_df['OverallGrade'] = all_df['OverallQual'] * all_df['OverallCond']\n",
    "    if 'GarageQual' in all_df.columns and 'GarageCond' in all_df.columns:\n",
    "        all_df['GarageGrade'] = all_df['GarageQual'] * all_df['GarageCond']\n",
    "    if 'ExterQual' in all_df.columns and 'ExterCond' in all_df.columns:\n",
    "        all_df['ExterGrade'] = all_df['ExterQual'] * all_df['ExterCond']\n",
    "\n",
    "    if 'MSSubClass' in all_df.columns: all_df['MSSubClass'] = all_df['MSSubClass'].astype(str)\n",
    "\n",
    "    categorical_cols = [col for col in all_df.columns if all_df[col].dtype == 'object']\n",
    "    if 'MSSubClass' in all_df.columns and isinstance(all_df['MSSubClass'].dtype, pd.StringDtype):\n",
    "        if 'MSSubClass' not in categorical_cols: categorical_cols.append('MSSubClass')\n",
    "    elif 'MSSubClass' in all_df.columns and all_df['MSSubClass'].dtype == 'object':\n",
    "         if 'MSSubClass' not in categorical_cols: categorical_cols.append('MSSubClass')\n",
    "    \n",
    "    if categorical_cols:\n",
    "        all_df = pd.get_dummies(all_df, columns=categorical_cols, dummy_na=False, dtype=int)\n",
    "\n",
    "    train_processed = all_df.iloc[:split_point]\n",
    "    test_processed = all_df.iloc[split_point:]\n",
    "    \n",
    "    print(f\"Final processed train shape: {train_processed.shape}\")\n",
    "    print(f\"Final processed test shape: {test_processed.shape}\")\n",
    "\n",
    "    if y_train_full is not None:\n",
    "        train_processed = train_processed.copy() \n",
    "        train_processed.loc[:, 'SalePrice'] = y_train_full.values\n",
    "\n",
    "    return train_processed, test_processed, test_ids\n",
    "\n",
    "# ==============================================\n",
    "# MODEL SIECI NEURONOWEJ\n",
    "# ==============================================\n",
    "class HousePriceModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_layers, dropout_rate=0.2, use_dropout=True):\n",
    "        super(HousePriceModel, self).__init__()\n",
    "        layers = []\n",
    "        prev_layer_size = input_dim\n",
    "        for layer_size in hidden_layers:\n",
    "            layers.append(nn.Linear(prev_layer_size, layer_size))\n",
    "            layers.append(nn.BatchNorm1d(layer_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            if use_dropout: layers.append(nn.Dropout(dropout_rate))\n",
    "            prev_layer_size = layer_size\n",
    "        layers.append(nn.Linear(prev_layer_size, 1))\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x): return self.net(x)\n",
    "\n",
    "# ==============================================\n",
    "# Funkcje treningu i metryk \n",
    "# ==============================================\n",
    "def train_model(model, train_loader, val_loader, optimizer, criterion, epochs, patience, device, model_save_path, scheduler=None):\n",
    "    \n",
    "    pass\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, context=\"\"):\n",
    "   \n",
    "    y_true_flat, y_pred_flat = y_true.flatten(), y_pred.flatten()\n",
    "    if len(y_true_flat) == 0 or len(y_pred_flat) == 0 or len(y_true_flat) != len(y_pred_flat):\n",
    "        return np.nan, np.nan, np.nan, np.nan\n",
    "    valid_indices = ~ (np.isnan(y_true_flat) | np.isinf(y_true_flat) | np.isnan(y_pred_flat) | np.isinf(y_pred_flat))\n",
    "    y_true_clean, y_pred_clean = y_true_flat[valid_indices], y_pred_flat[valid_indices]\n",
    "    if len(y_true_clean) == 0: return np.nan, np.nan, np.nan, np.nan\n",
    "\n",
    "    r2 = np.nan\n",
    "    if len(y_true_clean) >= 1 and not (np.var(y_true_clean) < 1e-9):\n",
    "        try: r2 = r2_score(y_true_clean, y_pred_clean)\n",
    "        except ValueError: pass \n",
    "    elif np.var(y_true_clean) < 1e-9 : \n",
    "         r2 = 0.0 if np.var(y_pred_clean) < 1e-9 and np.abs(np.mean(y_true_clean) - np.mean(y_pred_clean)) < 1e-9 else np.nan\n",
    "\n",
    "\n",
    "    mse = mean_squared_error(y_true_clean, y_pred_clean); rmse = np.sqrt(mse)\n",
    "    rmsle = np.nan\n",
    "    y_true_rmsle, y_pred_rmsle = y_true_clean.copy(), y_pred_clean.copy()\n",
    "    if np.any(y_pred_rmsle < 0): y_pred_rmsle[y_pred_rmsle < 0] = 0\n",
    "    if not np.any(y_true_rmsle < 0) and len(y_true_rmsle) > 0:\n",
    "        try:\n",
    "            log_y_true, log_y_pred = np.log1p(y_true_rmsle), np.log1p(y_pred_rmsle)\n",
    "            if not (np.any(np.isinf(log_y_true)) or np.any(np.isinf(log_y_pred)) or \\\n",
    "                    np.any(np.isnan(log_y_true)) or np.any(np.isnan(log_y_pred))):\n",
    "                rmsle = np.sqrt(mean_squared_error(log_y_true, log_y_pred))\n",
    "        except Exception: pass \n",
    "    return mse, rmse, r2, rmsle\n",
    "\n",
    "# ==============================================\n",
    "# GŁÓWNY BLOK WYKONAWCZY \n",
    "# ==============================================\n",
    "def main():\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "    np.random.seed(config[\"random_state\"])\n",
    "    torch.manual_seed(config[\"random_state\"])\n",
    "    if device.type == 'cuda': torch.cuda.manual_seed_all(config[\"random_state\"])\n",
    "\n",
    "    \n",
    "    train_df_orig, test_df_orig = load_data()\n",
    "    train_df, test_df, test_ids = preprocess_data(train_df_orig.copy(), test_df_orig.copy(), config[\"target_transform\"])\n",
    "    \n",
    "    if 'SalePrice' not in train_df.columns:\n",
    "        if config[\"target_transform\"]: y = np.log1p(train_df_orig['SalePrice']); X = train_df\n",
    "        else: raise ValueError(\"'SalePrice' missing and target_transform is False.\")\n",
    "    else: X = train_df.drop('SalePrice', axis=1); y = train_df['SalePrice']\n",
    "    \n",
    "    non_numeric_cols = X.select_dtypes(exclude=np.number).columns\n",
    "    if len(non_numeric_cols) > 0:\n",
    "        print(f\"Warning: Non-numeric columns in X before scaling: {list(non_numeric_cols)}. Converting.\")\n",
    "        for col in non_numeric_cols: X.loc[:, col] = pd.to_numeric(X[col], errors='coerce').fillna(0)\n",
    "    \n",
    "    missing_cols_in_test = set(X.columns) - set(test_df.columns)\n",
    "    for c in missing_cols_in_test: test_df.loc[:, c] = 0\n",
    "    extra_cols_in_test = set(test_df.columns) - set(X.columns)\n",
    "    if extra_cols_in_test: test_df = test_df.drop(columns=list(extra_cols_in_test))\n",
    "    test_df = test_df[X.columns]\n",
    "\n",
    "    \n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=config[\"validation_size\"], random_state=config[\"random_state\"])\n",
    "    \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    \n",
    "    X_test_scaled = scaler.transform(test_df)\n",
    "    \n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "    # =========================================================================\n",
    "    # GŁÓWNA ZMIANA: WCZYTANIE MODELU ZAMIAST TRENINGU\n",
    "    # =========================================================================\n",
    "    print(\"\\n--- Tryb Predykcji: Pomijanie treningu, wczytywanie modelu z pliku ---\")\n",
    "\n",
    "    input_dim = X_test_tensor.shape[1]\n",
    "    model = HousePriceModel(\n",
    "        input_dim, \n",
    "        config[\"hidden_layers\"], \n",
    "        config[\"dropout_rate\"], \n",
    "        config[\"use_dropout\"]\n",
    "    ).to(device)\n",
    "\n",
    "    model_path = config[\"model_save_path\"]\n",
    "    try:\n",
    "        \n",
    "        model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "        print(f\"Pomyślnie wczytano model z pliku: {model_path}\")\n",
    "    except FileNotFoundError:\n",
    "        print(f\"BŁĄD KRYTYCZNY: Nie znaleziono pliku modelu '{model_path}'.\")\n",
    "        print(\"Nie można kontynuować. Uruchom skrypt w trybie treningu, aby zapisać model.\")\n",
    "        return \n",
    "\n",
    "    model.eval()\n",
    "\n",
    "   \n",
    "    print(\"\\nGenerowanie predykcji dla zbioru testowego...\")\n",
    "    with torch.no_grad():\n",
    "        test_predictions_scaled = model(X_test_tensor.to(device)).cpu().numpy()\n",
    "\n",
    "    clip_min, clip_max = -20, 25 \n",
    "    test_predictions_scaled_clipped = np.clip(test_predictions_scaled, clip_min, clip_max)\n",
    "    \n",
    "    if config[\"target_transform\"]:\n",
    "        final_test_predictions = np.expm1(test_predictions_scaled_clipped.flatten())\n",
    "    else:\n",
    "        final_test_predictions = test_predictions_scaled_clipped.flatten()\n",
    "        \n",
    "    final_test_predictions[final_test_predictions < 0] = 0 \n",
    "    \n",
    "    submission_df = pd.DataFrame({'Id': test_ids, 'SalePrice': final_test_predictions})\n",
    "    submission_df.to_csv(config[\"submission_file_name\"], index=False) \n",
    "    print(f\"Zapisano przewidywania ({len(final_test_predictions)} wierszy) do pliku {config['submission_file_name']}\")\n",
    "    print(\"\\nZakończono.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89788d0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
